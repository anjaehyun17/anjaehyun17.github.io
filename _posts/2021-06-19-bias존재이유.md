---
layout: post
title: "bias 존재 이유"
tag:
- bias
- perceptron


---


### bias 존재 이유 

perceptron을 간단히 수식으로 표현하면 y=wx+b로 표현이 가능하다.

	1. 이때 bias를 보통 1을 준다.
	2. wx를 계산하고 +bias를 해주어도 되지만, w에 길이를 1 늘리고, x(features)에 1를 concat하는 방식으로 학습할 수도 있다.
	3. bias가 왜 필요하냐면 wx(기울기), bias(절편),  wx만 있다면 무조건 0을 지나야하기 때문에 bias를 두어 y축을 이동가능해 진다. 
	4. 이 정도로 이해해도 무방한가? 조금 더 흥미로운 것을 찾았는데 bias는 wx가 가져야할 최소 기준이라는 관점이다. 
	5. wx+b > 1 이 활성상태라고 본다면, wx > 1-b (bias가 1이라면 wx가 최소 양수가 되어야 한다는 점이다)
	6. bias가 일반적으로 1로 주고 많이 사용하지만, 경우에 따라 조절을 해야하는 경우가 있을지도 모르겠다. 꽤 흥미로운 새로운 지식이다.
	{: style="text-align: left;"}

{: style="text-align: left;"}

